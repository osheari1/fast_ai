{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, importlib\n",
    "import utils; importlib.reload(utils)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import keras\n",
    "import sklearn\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from os.path import join as jp\n",
    "\n",
    "from keras import models, optimizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Struct Dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For this comp, need to stratify the valid set based on the drivers as well as the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = '../data/statefarm/'\n",
    "cats = pd.read_csv('../data/statefarm/driver_imgs_list.csv').set_index('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "utils.create_dirs(path, cats.classname.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Move 20% of each class, stratified by subject, into valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for cl in cats.classname.unique():\n",
    "    imgs_train, imgs_valid = train_test_split(cats[cats.classname == cl].index,\n",
    "                                              test_size=0.2,\n",
    "                                              stratify=cats[cats.classname == cl].subject)\n",
    "    for img in imgs_valid:\n",
    "        cats.ix[img, 'split'] = 'valid'\n",
    "        shutil.move(os.path.join(path, 'train', cl, img),\n",
    "                    os.path.join(path, 'valid', cl))\n",
    "cats.split.fillna('train', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Copy about 100 from each class into sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n"
     ]
    }
   ],
   "source": [
    "for cl in cats.classname.unique():\n",
    "    cats_train = cats[(cats.classname == cl) & (cats.split == 'train')]\n",
    "    cats_valid = cats[(cats.classname == cl) & (cats.split == 'valid')]\n",
    "    \n",
    "    # Remove any subjects that only have 1 occurence in either set\n",
    "    cats_valid_cnts = cats_valid.subject.value_counts()\n",
    "    cats_train_cnts = cats_train.subject.value_counts()\n",
    "    cats_valid_keep = cats_valid_cnts[cats_valid_cnts > 1].index.values\n",
    "    cats_train_keep = cats_train_cnts[cats_train_cnts > 1].index.values\n",
    "    cats_valid = cats_valid[cats_valid.subject.isin(cats_valid_keep)]    \n",
    "    cats_train = cats_train[cats_train.subject.isin(cats_train_keep)]    \n",
    "    \n",
    "    # Split data\n",
    "    _, imgs_train = train_test_split(cats_train.index,\n",
    "                                     test_size=100,\n",
    "                                     stratify=cats_train.subject)\n",
    "    _, imgs_valid = train_test_split(cats_valid.index,\n",
    "                                     test_size=100,\n",
    "                                     stratify=cats_valid.subject)\n",
    "    for img_tr, img_v in zip(imgs_train, imgs_valid):\n",
    "        shutil.copy(jp(path, 'train', cl, img_tr),\n",
    "                    jp(path, 'sample', 'train', cl, img_tr))\n",
    "        shutil.copy(jp(path, 'valid', cl, img_v),\n",
    "                    jp(path, 'sample', 'valid', cl, img_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Copy test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = np.random.choice(glob(jp(path, 'test', 'test', '*.jpg')), 100, replace=False)\n",
    "for img in files:\n",
    "    shutil.copy(img, jp(path, 'sample', 'test', 'test', img.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# path = '../data/statefarm/'\n",
    "path = '../data/statefarm/sample/'\n",
    "path_model = '../data/statefarm/models/'\n",
    "path_test = path + 'test'\n",
    "path_train = path + 'train'\n",
    "path_valid = path + 'valid'\n",
    "path_img_arrays = path + 'img_arrays/'\n",
    "\n",
    "path_submit = path_model + 'submissions/'\n",
    "path_checkpoint = path_model + 'checkpoints/'\n",
    "path_results = path_model + 'results/'\n",
    "\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches_train = utils.get_batches(path+'train', batch_size=batch_size)\n",
    "batches_valid = utils.get_batches(path+'valid', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "classes, filenames = utils.get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_linear = models.Sequential([\n",
    "        BatchNormalization(axis=3, input_shape=(224, 224, 3)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')     \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_linear.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 31s - loss: 14.3575 - acc: 0.1030 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 25s - loss: 14.3873 - acc: 0.1060 - val_loss: 9.7031 - val_acc: 0.3980\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 25s - loss: 14.4096 - acc: 0.1060 - val_loss: 14.9737 - val_acc: 0.0710\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 25s - loss: 14.4096 - acc: 0.1060 - val_loss: 15.8901 - val_acc: 0.0130\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 25s - loss: 14.4096 - acc: 0.1060 - val_loss: 16.0386 - val_acc: 0.0040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf68642518>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear.fit_generator(batches_train, samples_per_epoch=batches_train.n,\n",
    "                           validation_data=baches_valid, nb_val_samples=batches_valid.n,\n",
    "                           nb_epoch=5, callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Model isnt doing anything, lower lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 26s - loss: 2.3173 - acc: 0.2490 - val_loss: 1.8748 - val_acc: 0.3430\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 25s - loss: 1.3051 - acc: 0.5790 - val_loss: 1.2341 - val_acc: 0.5570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf682b0be0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear = models.Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224, 224, 3)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')     \n",
    "    ])\n",
    "model_linear.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_linear.fit_generator(batches_train, samples_per_epoch=batches_train.n,\n",
    "                           validation_data=baches_valid, nb_val_samples=batches_valid.n,\n",
    "                           nb_epoch=2, callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "Increase lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model_linear.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1000/1000 [==============================] - 26s - loss: 3.0042 - acc: 0.5600 - val_loss: 1.8723 - val_acc: 0.6950\n",
      "Epoch 2/4\n",
      "1000/1000 [==============================] - 25s - loss: 1.4681 - acc: 0.7440 - val_loss: 1.9966 - val_acc: 0.7310\n",
      "Epoch 3/4\n",
      "1000/1000 [==============================] - 25s - loss: 0.8713 - acc: 0.8410 - val_loss: 1.0877 - val_acc: 0.8224\n",
      "Epoch 4/4\n",
      "1000/1000 [==============================] - 25s - loss: 0.4035 - acc: 0.8980 - val_loss: 0.8628 - val_acc: 0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf68236a58>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear.fit_generator(batches_train, samples_per_epoch=batches_train.n,\n",
    "                           validation_data=baches_valid, nb_val_samples=batches_valid.n,\n",
    "                           nb_epoch=4, callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "acc_valid stablizes around 82. Generate random valid batches to see if there is sampling bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches_rand = utils.get_batches(jp(path, 'valid'), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_scores = [model_linear.evaluate_generator(batches_rand, batches_rand.n/10)\n",
    "              for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.21,  0.79],\n",
       "       [ 0.89,  0.84],\n",
       "       [ 0.83,  0.83],\n",
       "       [ 1.09,  0.82],\n",
       "       [ 1.14,  0.81],\n",
       "       [ 1.06,  0.79],\n",
       "       [ 1.57,  0.78],\n",
       "       [ 0.91,  0.77],\n",
       "       [ 0.81,  0.81],\n",
       "       [ 1.12,  0.81]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(val_scores, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Linear Model with Maxout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 26s - loss: 6.7963 - acc: 0.1230 - val_loss: 5.0418 - val_acc: 0.2570\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 25s - loss: 3.8167 - acc: 0.2760 - val_loss: 3.2944 - val_acc: 0.3460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf44237d68>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear_mo = models.Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(224, 224, 3)),\n",
    "        Flatten(),\n",
    "        MaxoutDense(10),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "model_linear_mo.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_linear_mo.fit_generator(batches_train, samples_per_epoch=batches_train.n,\n",
    "                           validation_data=baches_valid, nb_val_samples=batches_valid.n,\n",
    "                           nb_epoch=2, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model_linear.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 25s - loss: 1.5415 - acc: 0.5800 - val_loss: 2.7848 - val_acc: 0.4222\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 24s - loss: 0.9965 - acc: 0.7110 - val_loss: 1.8750 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 24s - loss: 0.6589 - acc: 0.8110 - val_loss: 1.8518 - val_acc: 0.5450\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 25s - loss: 0.4296 - acc: 0.8770 - val_loss: 1.4340 - val_acc: 0.6210\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 25s - loss: 0.2806 - acc: 0.9370 - val_loss: 1.6638 - val_acc: 0.6220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf68236828>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear_mo.fit_generator(batches_train, samples_per_epoch=batches_train.n,\n",
    "                           validation_data=baches_valid, nb_val_samples=batches_valid.n,\n",
    "                           nb_epoch=5, callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 26s - loss: 10.3370 - acc: 0.1920 - val_loss: 11.0494 - val_acc: 0.2330\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 25s - loss: 9.5793 - acc: 0.2880 - val_loss: 10.3611 - val_acc: 0.3430\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 25s - loss: 9.3116 - acc: 0.3430 - val_loss: 10.8533 - val_acc: 0.1856\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 25s - loss: 6.9767 - acc: 0.4680 - val_loss: 7.9728 - val_acc: 0.4760\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 25s - loss: 5.8017 - acc: 0.5820 - val_loss: 1.4761 - val_acc: 0.7570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf307b1ac8>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear_l2 = models.Sequential([\n",
    "        BatchNormalization(axis=3, input_shape=(224, 224, 3)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax', W_regularizer=regularizers.l2(l=0.01))     \n",
    "    ])\n",
    "model_linear_l2.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_linear_l2.fit_generator(batches_train, samples_per_epoch=batches_train.n,\n",
    "                           validation_data=baches_valid, nb_val_samples=batches_valid.n,\n",
    "                           nb_epoch=5, callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Conv Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_model_conv(batches, epochs2=4):\n",
    "    model_conv = models.Sequential([\n",
    "            BatchNormalization(axis=3, input_shape=(224, 224, 3)),\n",
    "            Convolution2D(32, 3, 3, activation='relu'),\n",
    "            BatchNormalization(axis=3),\n",
    "            MaxPooling2D((3, 3)),\n",
    "            Convolution2D(64, 3, 3, activation='relu'),\n",
    "            BatchNormalization(axis=3),\n",
    "            MaxPooling2D((3, 3)),\n",
    "            Flatten(),\n",
    "            MaxoutDense(100),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model_conv.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model_conv.fit_generator(batches, samples_per_epoch=batches.n,\n",
    "                         validation_data=batches_valid, nb_val_samples=batches_valid.n,\n",
    "                         nb_epoch=2, callbacks=None)\n",
    "    K.set_value(model_conv.optimizer.lr, 1e-3)\n",
    "    model_conv.fit_generator(batches, samples_per_epoch=batches.n,\n",
    "                         validation_data=batches_valid, nb_val_samples=batches_valid.n,\n",
    "                         nb_epoch=epochs2, callbacks=None)\n",
    "    return model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 57s - loss: 1.9145 - acc: 0.3880 - val_loss: 3.1522 - val_acc: 0.1220\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 55s - loss: 0.4965 - acc: 0.9000 - val_loss: 2.8061 - val_acc: 0.1890\n",
      "Epoch 1/4\n",
      "1000/1000 [==============================] - 60s - loss: 1.1152 - acc: 0.6550 - val_loss: 1.1022 - val_acc: 0.5590\n",
      "Epoch 2/4\n",
      "1000/1000 [==============================] - 61s - loss: 0.2055 - acc: 0.9650 - val_loss: 0.7434 - val_acc: 0.7510\n",
      "Epoch 3/4\n",
      "1000/1000 [==============================] - 62s - loss: 0.0418 - acc: 0.9980 - val_loss: 0.3475 - val_acc: 0.9060\n",
      "Epoch 4/4\n",
      "1000/1000 [==============================] - 64s - loss: 0.0155 - acc: 0.9980 - val_loss: 0.2117 - val_acc: 0.9480\n"
     ]
    }
   ],
   "source": [
    "model_conv = gen_model_conv(batches_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv model trains very quickly. Add regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test different data augmentations to find best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Width Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1)\n",
    "batches_train = utils.get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 55s - loss: 2.4474 - acc: 0.2230 - val_loss: 2.4816 - val_acc: 0.1650\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 56s - loss: 1.5380 - acc: 0.5050 - val_loss: 1.8161 - val_acc: 0.2910\n",
      "Epoch 1/4\n",
      "1000/1000 [==============================] - 59s - loss: 1.8985 - acc: 0.3780 - val_loss: 1.4240 - val_acc: 0.5780\n",
      "Epoch 2/4\n",
      "1000/1000 [==============================] - 61s - loss: 1.2066 - acc: 0.6200 - val_loss: 1.1095 - val_acc: 0.6370\n",
      "Epoch 3/4\n",
      "1000/1000 [==============================] - 62s - loss: 0.8812 - acc: 0.7220 - val_loss: 0.7807 - val_acc: 0.7390\n",
      "Epoch 4/4\n",
      "1000/1000 [==============================] - 63s - loss: 0.7060 - acc: 0.7890 - val_loss: 0.6498 - val_acc: 0.7920\n"
     ]
    }
   ],
   "source": [
    "model = gen_model_conv(batches_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:default]",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
