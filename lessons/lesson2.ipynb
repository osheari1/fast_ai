{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, importlib\n",
    "import utils; importlib.reload(utils)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from os.path import join as jp\n",
    "\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory structure already exists\n"
     ]
    }
   ],
   "source": [
    "path = '../data/dogscats/'\n",
    "utils.struct_dir(path, ['cat', 'dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# path = '../data/dogscats/'\n",
    "path = '../data/dogscats/sample/'\n",
    "path_test = path + 'test'\n",
    "path_train = path + 'train'\n",
    "path_valid = path + 'valid'\n",
    "path_submit = '../data/dogscats/models/vgg16/submissions/'\n",
    "path_checkpoint = '../data/dogscats/models/vgg16/checkpoints/'\n",
    "path_results = '../data/dogscats/models/vgg16/results/'\n",
    "path_img_arrays = '../data/dogscats/models/vgg16/img_arrays/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import vgg16; importlib.reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights\n"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Save images in array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# batches_train = utils.get_batches(path_train, batch_size=batch_size)\n",
    "# batches_valid = utils.get_batches(path_valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# utils.save_array_h5(path_img_arrays+'train.h5', utils.get_data(path_train))\n",
    "# utils.save_array_h5(path_img_arrays+'valid.h5', utils.get_data(path_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n",
      "Found 100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_train = utils.load_array_h5(path_img_arrays+'train.h5')\n",
    "data_valid = utils.load_array_h5(path_img_arrays+'valid.h5')\n",
    "classes, filenames = utils.get_classes(path)\n",
    "labels_train = classes[2]\n",
    "labels_valid = classes[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Last Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove last layer and freeze previous layers\n",
    "- Train last layer\n",
    "- Evaluate valid set\n",
    "- Create confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pop, Freeze and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 224, 224, 3)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 226, 226, 3)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 224, 224, 64)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 226, 226, 64)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 224, 224, 64)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 112, 112, 64)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 114, 114, 64)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 112, 112, 128) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 114, 114, 128) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 112, 112, 128) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 56, 56, 128)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 58, 58, 128)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 56, 56, 256)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 58, 58, 256)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 56, 56, 256)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 58, 58, 256)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 56, 56, 256)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 28, 28, 256)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 30, 30, 256)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 28, 28, 512)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 30, 30, 512)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 28, 28, 512)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 30, 30, 512)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 28, 28, 512)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 14, 14, 512)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 16, 16, 512)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 14, 14, 512)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 16, 16, 512)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 14, 14, 512)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 16, 16, 512)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 14, 14, 512)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 7, 7, 512)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1000)          4097000     dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.ft(num=2, compile_kwargs={'lr': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??vgg.finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??vgg.ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches_train = gen.flow(data_train, labels_train, batch_size=batch_size, shuffle=True)\n",
    "batches_valid = gen.flow(data_valid, labels_valid, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??vgg.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 52s - loss: 3.0223 - acc: 0.7600 - val_loss: 1.4003 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "file_weights = 'weights_2.h5'\n",
    "callbacks = [ModelCheckpoint(path_checkpoint+file_weights, save_best_only=True)]\n",
    "vgg.fit(batches_train, batches_valid, nb_epoch=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(path_checkpoint+file_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Evaluate on valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vgg.model.metrics_names)\n",
    "vgg.model.evaluate(data_valid, labels_valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 15s    \n",
      "100/100 [==============================] - 14s    \n"
     ]
    }
   ],
   "source": [
    "preds = vgg.model.predict_classes(data_valid, batch_size=batch_size)\n",
    "probs = vgg.model.predict_proba(data_valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fec725e16d8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFoCAYAAAAWz/GVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB90xovJMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec727e5780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_conf_matrix(classes[1], preds, {'cat': 0, 'dog': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finetune final layer (if not done already)\n",
    "- Find the first dense layer\n",
    "- Freeze all previous layers and set all layers after D1 to trainable\n",
    "- Update learning rate (decreaese) and fit model\n",
    "- Save/Load checkpoint\n",
    "- Retrain some conv layers\n",
    "- Save/load checkpoint\n",
    "- Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Find and Un-freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1 Trainable: True\n",
      "dropout_1 Trainable: True\n",
      "dense_2 Trainable: True\n",
      "dropout_2 Trainable: True\n",
      "dense_4 Trainable: True\n"
     ]
    }
   ],
   "source": [
    "idx_fdense = [i for i, layer in enumerate(vgg.model.layers) if type(layer) is layers.Dense][0]\n",
    "\n",
    "for layer in vgg.model.layers[idx_fdense:]: \n",
    "    layer.trainable = True\n",
    "    print(layer.name, 'Trainable: %s' % layer.trainable)          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Update Learning Rate, Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??vgg.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# vgg.compile(lr=0.01)\n",
    "K.set_value(vgg.model.optimizer.lr, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 32s - loss: 2.5293 - acc: 0.8400 - val_loss: 2.0292 - val_acc: 0.8600\n"
     ]
    }
   ],
   "source": [
    "file_weights = 'weights_3.h5'\n",
    "callbacks = [ModelCheckpoint(path_checkpoint+file_weights, save_best_only=True)]\n",
    "vgg.fit(batches_train, batches_valid, nb_epoch=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(path_checkpoint+file_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Retrain Conv Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'convolution2d_1'),\n",
       " (4, 'convolution2d_2'),\n",
       " (7, 'convolution2d_3'),\n",
       " (9, 'convolution2d_4'),\n",
       " (12, 'convolution2d_5'),\n",
       " (14, 'convolution2d_6'),\n",
       " (16, 'convolution2d_7'),\n",
       " (19, 'convolution2d_8'),\n",
       " (21, 'convolution2d_9'),\n",
       " (23, 'convolution2d_10'),\n",
       " (26, 'convolution2d_11'),\n",
       " (28, 'convolution2d_12'),\n",
       " (30, 'convolution2d_13')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_conv = [(i, l.name) for i, l in enumerate(vgg.model.layers) if type(l) is layers.Conv2D]\n",
    "idx_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg.model.layers[26:]: layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "K.set_value(vgg.model.optimizer.lr, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 31s - loss: 1.9279 - acc: 0.8600 - val_loss: 1.3450 - val_acc: 0.8900\n"
     ]
    }
   ],
   "source": [
    "file_weights = 'weights_4.h5'\n",
    "callbacks = [ModelCheckpoint(path_checkpoint+file_weights, save_best_only=True)]\n",
    "vgg.fit(batches_train, batches_valid, nb_epoch=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(path_checkpoint+file_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 14s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2834900689125146, 0.90000000000000002]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.model.evaluate(data_valid, labels_valid, batch_size=batch_size, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches_test, probs_test = vgg.test(path_test, batch_size=batch_size)\n",
    "np.save(path_results+'filenames_test.npy', batches_test.filenames)\n",
    "np.save(path_results+'probs_test.npy', probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.create_submit(batches_test, probs_test[:, 1], clip=(0, 1), fname=path_submit+'submit_1.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:default]",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
